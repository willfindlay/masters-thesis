This chapter presents an evaluation of \bpfbox{} and \bpfcontain{} in terms of their
performance and security. \Cref{s:eval-performance} presents the methodology and results
of a performance evaluation involving micro- and macro-benchmarking of \bpfbox{} and
\bpfcontain{}. Results are compared with AppArmor~\cite{cowan2000_apparmor}, a popular
\gls{lsm} framework for \gls{mac} security policy. Finally, \Cref{s:eval-security}
presents a security analysis of \bpfbox{} and \bpfcontain{} under the threat model
outlined in \Cref{s:cp-threat-model} of \Cref{c:confinement-problem}.

\section{Performance Evaluation}%
\label{s:eval-performance}

This section presents a performance evaluation of \bpfbox{} and \bpfcontain{}, measuring
their performance overhead using a variety of benchmarking tests. In particular, we
leverage the Phoronix Test Suite~\cite{phoronix} to measure overhead across a variety of
computational tasks, workloads, and kernel interfaces. Each of these benchmarks exercises
a different subset of \bpfbox{} and \bpfcontain{}'s enforcement engine, providing a good
approximation of their impact on the overall system. The subsections that follow provide an
overview of the testing methodology and present the benchmark results.

\subsection{Methodology}%
\label{ss:eval-methodology}

For the test environment, we utilize a bare-metal system running Arch Linux with a stock
5.12.14-arch-1-1 kernel. The choice of a bare-metal system reduces the risk of introducing
additional sources of variance into the benchmarks. \Cref{tab:system-config} provides
a detailed account of system configuration for the test system.

\begin{table}[htpb]
  \centering
  \caption[System configuration for benchmarking tests]{System configuration for benchmarking tests.}%
  \label{tab:system-config}
  \begin{tabular}{ll}
  \toprule
  Item & Description / Configuration \\
  \midrule
  CPU & Intel i7-10875H; 8 cores, 16 threads at 2.3GHz; 16MB cache\\
  GPU & Nvidia RTX 2060 with 6GB GDDR6 VRAM \\
  RAM & 2$\times$16GB DDR4 at 3.2GHz \\
  Disk & 1TiB Samsung NVME M.2 SSD \\
  \midrule
  \gls{os} & Arch Linux (Rolling) \\
  Kernel & Linux 5.12.14-arch-1-1 \\
  Libc & glibc v2.33-5 \\
  \bottomrule
  \end{tabular}
\end{table}

\begin{inprogress}
  \begin{itemize}
    \item Test environment
    \begin{itemize}
      \item Describe system specs
      \item To improve benchmark accuracy, we disable ...
      \item We run tests in a privileged Docker container
      \item Arch Linux Kernel 5.12.15-arch-1
    \end{itemize}

    \item Phoronix Test Suite tests
    \begin{itemize}
      \item \todo{Describe each test in detail and explain what LSM hooks it exercises}
    \end{itemize}

    \item \todo{Other tests if we have time}

    \item Explain each test case (base, \{bpfbox, bpfcontain, apparmor\}, \{passive, allow, complaining\})
    \item Run reach test for at least 11 trials, until we achieve an acceptable standard deviation ($<2\%$)
    \item Discard first run of each trial, to control for initial I/O transients and caching
    \item Reproducibility, give \bpfbox{} and \bpfcontain{} version, with tags on GitHub
    \item Link to the benchmarking repo

  \end{itemize}
\end{inprogress}

\subsection{Results}%
\label{ss:eval-results}

\todo{Present each test, table of results, perhaps a graph of results. Accompany each test with some text explaining the result}

\subsubsection{OSBench Results}

\subsubsection{Kernel Compilation Results}

\subsubsection{Apache Webserver Results}

\subsection{Discussion of Results}%
\label{ss:eval-performance-discussion}

\begin{table}[htbp]
  \centering
  \caption[Geometric means of Phoronix benchmarking results]{
    Geometric means of Phoronix benchmarking results.  These are indicative of over all
    performance across all tests.  For each configuration, percent change from the base
    result is also given.  Higher values are better.
  }%
  \label{tab:phoronix-geometric}
  \begin{tabular}{llrr}
  \toprule
  System                        & Configuration & Geom. Mean & Percent Change (Base)\\
  \midrule
  Base                          & ---           & 6.238          & --- \\
  \midrule
  \multirow{3}{*}{AppArmor}     & Passive       & 6.158          &  -1.28\% \\
                                & Allow         & 6.086          &  -2.35\% \\
                                & Complain      & 4.962          & -20.46\% \\
  \midrule
  \multirow{3}{*}{BPFBox}       & Passive       & 6.007          & -3.70\% \\
                                & Allow         & 5.944          & -4.71\% \\
                                & Complain      & 5.823          & -6.65\% \\
  \midrule
  \multirow{3}{*}{BPFContain}   & Passive       & 5.951          & -4.60\% \\
                                & Allow         & 5.763          & -7.61\% \\
                                & Complain      & 5.693          & -8.74\% \\
  \bottomrule
  \end{tabular}
\end{table}

\begin{inprogress}
  \todo{Discuss a comparison with SELinux at the end, perhaps citing Zhang et al?}
  \begin{itemize}
    \item Zhang \etal~\cite{zhang2021_lsm_file_overhead} evaluated the performance
    overhead of LSMs on file system operations; they mentioned (really damning) performance
    statistics for SELinux that can be compared with BPFContain and AppArmor
  \end{itemize}
\end{inprogress}

\section{Security Analysis}%
\label{s:eval-security}



\section{Summary}%
\label{s:eval-summary}
